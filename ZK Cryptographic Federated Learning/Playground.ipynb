{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semester Project for Coding for Private Reliable and Efficient Distributed Learning \n",
    "## Winter Semester 2025\n",
    "## Ivan von Greif and Ata Shaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Block Overview\n",
    "\n",
    "- **JAX & Submodules:**  \n",
    "  High-performance numerical computing with automatic differentiation and support for GPUs/TPUs.\n",
    "\n",
    "- **Flax:**  \n",
    "  Neural network framework built on JAX, offering a high-level API (Linen) and immutable data structures.\n",
    "\n",
    "- **Optax:**  \n",
    "  Optimization and gradient processing tools designed for JAX.\n",
    "\n",
    "- **TensorFlow & TFDS:**  \n",
    "  Core deep learning library with an easy-to-use datasets interface.\n",
    "\n",
    "- **NumPy (as onp):**  \n",
    "  Standard numerical library for array operations, separate from JAX's numpy.\n",
    "\n",
    "- **CLU Metrics:**  \n",
    "  Utilities for tracking and computing performance metrics.\n",
    "\n",
    "- **functools.partial:**  \n",
    "  Simplifies function calls by pre-setting arguments.\n",
    "\n",
    "- **Matplotlib (mpl & pyplot):**  \n",
    "  Visualization library for creating plots and figures.\n",
    "\n",
    "- **Weights & Biases (wandb):**  \n",
    "  Experiment tracking and visualization tool.\n",
    "\n",
    "- **datetime:**  \n",
    "  For handling dates and timestamps.\n",
    "\n",
    "- **Pandas:**  \n",
    "  Data manipulation and analysis library for working with structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax import random as jrd\n",
    "from jax import tree as jtr\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "import optax\n",
    "from optax import tree_utils as otu\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as onp\n",
    "from clu import metrics\n",
    "from functools import partial\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Module Imports Overview\n",
    "\n",
    "- **Utils:**  \n",
    "  Imports all functions and classes from the `Utils` module, providing various utility functions.\n",
    "\n",
    "- **Training:**  \n",
    "  Imports everything from the `Training` module, likely containing training routines and helpers.\n",
    "\n",
    "- **Models:**  \n",
    "  Imports the `get_model` function from the `Models` module, used for creating or retrieving a model.\n",
    "\n",
    "- **Commons:**  \n",
    "  Imports all components from the `Commons` module, which may include shared functions or constants.\n",
    "\n",
    "- **Parameters_1 Configuration:**  \n",
    "  Imports the `config` object from `Params/Parameters_1` and aliases it as `cfg` for easy reference to configuration settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *\n",
    "from Training import *\n",
    "from Models import get_model\n",
    "from Commons import *\n",
    "from Params.Parameters_1 import config as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Key and Seed Initialization\n",
    "\n",
    "- **Generate JAX Key:**  \n",
    "  `key = jrd.key(cfg.seed)` initializes a JAX random key using the seed specified in the configuration (`cfg.seed`).\n",
    "\n",
    "- **Split the Key:**  \n",
    "  `key, tf_key = jrd.split(key, 2)` splits the original key into two separate keys: one for JAX and another (`tf_key`) for TensorFlow.\n",
    "\n",
    "- **Disable TensorFlow GPU Usage:**  \n",
    "  `tf.config.set_visible_devices([], \"GPU\")` disables GPU visibility for TensorFlow, forcing it to run on the CPU.\n",
    "\n",
    "- **Set TensorFlow Seed:**  \n",
    "  `tf.random.set_seed(jrd.key_data(tf_key)[0])` extracts a seed from the TensorFlow key (`tf_key`) and sets it as TensorFlow's random seed, ensuring reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-02-16 22:43:32,090:jax._src.xla_bridge:1018: Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1739742212.090995 35962475 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1739742212.108676 35962475 service.cc:145] XLA service 0x16cc88620 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739742212.108824 35962475 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1739742212.110402 35962475 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1739742212.110411 35962475 mps_client.cc:384] XLA backend will use up to 12884443136 bytes on device 0 for SimpleAllocator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M3 Pro\n",
      "\n",
      "systemMemory: 18.00 GB\n",
      "maxCacheSize: 6.00 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key = jrd.key(cfg.seed)\n",
    "key, tf_key = jrd.split(key, 2)\n",
    "\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "tf.random.set_seed(jrd.key_data(tf_key)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Client Setup\n",
    "\n",
    "- **Splitting Random Key for Data:**  \n",
    "  `key, data_key = jrd.split(key, 2)` splits the key for dataset-related randomness.\n",
    "\n",
    "- **Loading and Configuring Datasets:**  \n",
    "  Retrieves training and testing datasets with `get_datasets(data_key, cfg.data.name)`, and stores the data shape in `cfg.data.shape`.  \n",
    "  Prints the dataset shape and extracts images and labels from both training and testing datasets.\n",
    "\n",
    "- **Client Initialization and Configuration:**  \n",
    "  Sets `Client.data_shape` to the data shape and creates a list of client objects based on `cfg.worker.num`.  \n",
    "  Computes the number of classes from the training labels and updates `cfg.data.num_classes`.\n",
    "\n",
    "- **Additional Key Splitting for Tasks:**  \n",
    "  Splits the key into five parts for various operations (epochs, validation, training, and activity).\n",
    "\n",
    "- **Local Epoch Distribution:**  \n",
    "  `generate_local_epoch_distribution_JAX` assigns local epoch counts to clients based on multiple configuration parameters.\n",
    "\n",
    "- **Data Grouping by Class:**  \n",
    "  Uses `split_by_class_JAX` to organize training images and labels by class.\n",
    "\n",
    "- **Validation Data Sampling:**  \n",
    "  Samples a fixed number of validation examples per class using `sample_per_class_JAX`.\n",
    "\n",
    "- **Client Dataset Allocation:**  \n",
    "  `allocate_client_datasets_JAX` distributes training data among clients according to the allocation type, ratio, and other settings.\n",
    "\n",
    "- **Plotting Data Distribution:**  \n",
    "  Visualizes the distribution of labels across clients with `plot_data_distribution`.\n",
    "\n",
    "- **Generating Active Client Matrix:**  \n",
    "  Simulates client activity over server epochs using `generate_active_client_matrix_JAX`.\n",
    "\n",
    "- **Assigning Test and Validation Data:**  \n",
    "  Stores test images, test labels, and validation data within the `Client` class for later evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mnist...\n",
      "Data is of shape: (28, 28, 1)\n",
      "train_images is of shape: (60000, 28, 28, 1) and of type <class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "train_labels is of shape: (60000,) and of type <class 'jaxlib.xla_extension.ArrayImpl'>)\n",
      "The local iteration distribution is (10,) shaped\n",
      "The local iteration distribution is expanded to (50, 10)\n",
      "The number of dropped samples is equal to 40\n"
     ]
    }
   ],
   "source": [
    "key, data_key = jrd.split(key, 2)\n",
    "\n",
    "train_ds, test_ds, data_shape = get_datasets(data_key, cfg.data.name)\n",
    "cfg.data.shape = data_shape\n",
    "print('Data is of shape:', cfg.data.shape)\n",
    "train_images, train_labels = train_ds['image'], train_ds['label']\n",
    "test_images, test_labels = test_ds['image'], test_ds['label']\n",
    "print(f\"train_images is of shape: {train_images.shape} and of type {type(train_images)}\")\n",
    "print(f\"train_labels is of shape: {train_labels.shape} and of type {type(train_labels)})\")\n",
    "\n",
    "Client.data_shape = cfg.data.shape\n",
    "clients = [Client(client_id) for client_id in range(cfg.worker.num)]\n",
    "num_classes = len(onp.unique(train_labels))\n",
    "cfg.data.num_classes = num_classes\n",
    "\n",
    "key, epochs_key, validation_key, training_key, activity_key = jrd.split(key, 5)\n",
    "generate_local_epoch_distribution_JAX(epochs_key, clients, cfg.worker.epoch.type, cfg.worker.epoch.is_random, cfg.server.num_epochs,\n",
    "                                    cfg.worker.epoch.mean, cfg.worker.epoch.std, cfg.worker.epoch.beta, cfg.worker.epoch.coef)\n",
    "classed_data_and_labels = split_by_class_JAX(train_images, train_labels)\n",
    "valid_data, valid_labels = sample_per_class_JAX(validation_key, cfg.data.shape, cfg.data.num_validation, classed_data_and_labels)\n",
    "allocate_client_datasets_JAX(training_key, clients, cfg.data.alloc_type, cfg.data.alloc_ratio,\n",
    "                        num_classes, classed_data_and_labels, cfg.data.beta, cfg.data.shape)\n",
    "plot_data_distribution(cfg.worker.num, [client.labels for client in clients], cfg.wandb.name)\n",
    "generate_active_client_matrix_JAX(activity_key, clients, cfg.worker.inact_prob, cfg.server.num_epochs)\n",
    "\n",
    "Client.test_data = test_images\n",
    "Client.test_labels = test_labels\n",
    "Client.valid_data = valid_data\n",
    "Client.valid_labels = valid_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `poison_image`\n",
    "\n",
    "This function applies a \"poisoning\" operation to an image by inserting a patch with a specified pixel value, and optionally calculating the L2 norm difference between the original and modified image.\n",
    "\n",
    "#### Parameters:\n",
    "- **key (KeyArray):**  \n",
    "  A JAX random key used for randomness.\n",
    "  \n",
    "- **image (ArrayLike):**  \n",
    "  The input image array with shape `(H, W, C)`.\n",
    "\n",
    "- **poison_cfg (FrozenConfigDict):**  \n",
    "  Configuration settings for the poisoning process, including:\n",
    "  - **patch.size:**  \n",
    "    Size of the patch. It can be an integer or a tuple for height, width (and possibly channels).\n",
    "  - **patch.loc:**  \n",
    "    Location of the patch (either a fixed value or a tuple).\n",
    "  - **patch.loc_rad:**  \n",
    "    A radius that allows the patch location to vary randomly.\n",
    "  - **patch.val:**  \n",
    "    The pixel value used to fill the patch.\n",
    "  - **calc_l2_norm:**  \n",
    "    Boolean flag indicating whether to compute the L2 norm between the original and poisoned image.\n",
    "\n",
    "#### Process:\n",
    "1. **Extract Patch Dimensions:**  \n",
    "   Determines patch height and width from `poison_cfg.patch.size`.\n",
    "\n",
    "2. **Setup Patch Location and Value:**  \n",
    "   Retrieves the fixed location and allowed randomness (`patch.loc_rad`) along with the pixel value for the patch.\n",
    "\n",
    "3. **Patch Creation:**  \n",
    "   Creates a patch filled with the specified pixel value.\n",
    "\n",
    "4. **Randomness Handling:**  \n",
    "   Uses the random key to generate variations in the patch location if `patch_loc_radius` is greater than 0.\n",
    "\n",
    "5. **Patch Insertion:**  \n",
    "   Inserts the patch into the original image at the computed location using JAX's dynamic update.\n",
    "\n",
    "6. **Clipping:**  \n",
    "   Clamps the attacked image pixel values between 0.0 and 1.0.\n",
    "\n",
    "7. **L2 Norm Calculation:**  \n",
    "   Optionally computes the L2 norm of the difference between the original and the attacked image.\n",
    "\n",
    "8. **Return:**  \n",
    "   Outputs the modified image and the L2 norm (or 0.0 if not calculated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_image(key: KeyArray, image: ArrayLike, poison_cfg:FrozenConfigDict):\n",
    "    H, W, C = image.shape\n",
    "    patch_size = poison_cfg.patch.size  \n",
    "    if isinstance(patch_size, tuple):\n",
    "        patch_height, patch_width, patch_channel = patch_size\n",
    "    else:\n",
    "        patch_height = patch_width = patch_size\n",
    "\n",
    "    patch_loc = poison_cfg.patch.loc  # e.g., 0 or a tuple (x, y)\n",
    "    patch_loc_radius = poison_cfg.patch.loc_rad\n",
    "    patch_pixel_value = poison_cfg.patch.val\n",
    "    calc_l2_norm = poison_cfg.calc_l2_norm\n",
    "\n",
    "    if patch_height <= 0 or patch_width <= 0:\n",
    "        return image, 0.0\n",
    "\n",
    "    # patch = jnp.zeros((patch_height, patch_width, C))\n",
    "    # patch = patch.at[:, patch_height //2 ].set(patch_pixel_value)\n",
    "    # patch = patch.at[patch_width //2, : ].set(patch_pixel_value)\n",
    "    \n",
    "    patch = jnp.full((patch_height, patch_width, C), patch_pixel_value)\n",
    "\n",
    "    key, *subkeys = jrd.split(key, 5)\n",
    "    # if patch_loc == 0 or patch_loc is None:\n",
    "        # x = jrd.randint(subkeys[0], (), 0, H - patch_height + 1)\n",
    "        # y = jrd.randint(subkeys[1], (), 0, W - patch_width + 1)\n",
    "    # else:\n",
    "    x, y = patch_loc, patch_loc\n",
    "\n",
    "    if patch_loc_radius > 0.0:\n",
    "        radius = int(patch_loc_radius)\n",
    "        delta_x = jrd.randint(subkeys[2], (), -radius, radius + 1)\n",
    "        x = jnp.clip(x + delta_x, 0, H - patch_height)\n",
    "        y_variation = jnp.abs(radius - jnp.abs(delta_x))\n",
    "        sign = jrd.choice(subkeys[3], jnp.array([-1, 1]))\n",
    "        delta_y = sign * y_variation\n",
    "        y = jnp.clip(y + delta_y, 0, W - patch_width)\n",
    "\n",
    "    attacked_img = jax.lax.dynamic_update_slice(image, patch, (0, x, y))\n",
    "    # jax.debug.print(f\"{attacked_img[:5, :5]}\")\n",
    "    # attacked_img = image.at[x:x+patch_height, y:y+patch_width, :].set(patch)\n",
    "    attacked_img = jnp.clip(attacked_img, 0.0, 1.0)\n",
    "\n",
    "    if calc_l2_norm:\n",
    "        diff = image - attacked_img\n",
    "        l2_norm = jnp.linalg.norm(diff)\n",
    "    else:\n",
    "        l2_norm = 0.0\n",
    "\n",
    "    return attacked_img, l2_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisoning Client Data\n",
    "\n",
    "- **Iterate over Specified Clients:**  \n",
    "  For each client index in `cfg.data.poison.clients`, retrieve the corresponding client's data and labels.\n",
    "\n",
    "- **Select Attack Samples:**  \n",
    "  Identify indices where the label equals the source class (`cfg.data.poison.source_clss`) and compute the number of samples to attack based on `cfg.data.poison.ratio`.\n",
    "\n",
    "- **Random Permutation:**  \n",
    "  Use JAX's random splitting and permutation to randomly select the attack indices from the identified class indices.\n",
    "\n",
    "- **Apply the Poison Function:**  \n",
    "  Vectorize the `poison_image` function with `jax.vmap` to apply it over all selected attack samples, using separate subkeys for each sample.\n",
    "\n",
    "- **Update Data and Labels:**  \n",
    "  Replace the client's original data at the attack indices with the poisoned images and update the labels to the target class (`cfg.data.poison.target_clss`).\n",
    "\n",
    "- **Record Attack Indices:**  \n",
    "  Save the indices of the poisoned samples in `client.poisoned_idx` for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4746  519 5859 5452 3253 2073 1156  714 4433 3444 2636 4561    4 2173\n",
      "  864 1577 2300  802 2887 2136 2037 5937  304 3315  357 2558 4897 4315\n",
      " 3163  563 1764 2164 4753 5265 3820 4243 4409 3719 3087 5853  200 1543\n",
      " 5314 3531 2219 5467 2196 1400 5615 2826 2114 3994  927 3224 2302 5460\n",
      " 1458  491 2915 3363 5286 5837 1603  315 1007  504 5127 4581 1095 3304\n",
      " 2856 4172 5624 5812 3569 3898  705 4032 3654 4401 3056 5369 2293 3366\n",
      " 2523 1638 4901 4485 5462 5213 2381 4454 1286 2260 5958 2883  900 3470\n",
      " 5101 5347 4416 4545 3869  704 5004 4057 2690 3504]\n",
      "[1308 1960  739 2141 3712  136 1385 1730 1887 5949 5426 3927 2985 4349\n",
      " 3533 1603  446 5242 1021 4332 5247  766 4730 5679 4611 1918 2471 1610\n",
      " 1706 5848 5778 1083 3955 5162 1029 4816 2743 2870  807 4824 5436 3262\n",
      "  933  331 4201 1166 3886 2684 2667 2520 1556 3987 5087 4066 4924 5235\n",
      " 1789 5803 3089 5003 4115 1997 5671 2210 3117 1605 2924 1243 3010 3761\n",
      " 4397 1988 2700 1468 5807 4853  122 4893 3938 5838 5008  750 5435 3954\n",
      "   46 3065 1853 2890 1218  511   90 5589  304 4008 2703 3120 1441 5844\n",
      " 4862 4537 4949 4244  344 1916 1070 1596 4490  294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ata/Desktop/Me/myvenvmetal/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=int8 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for client_idx in cfg.data.poison.clients:\n",
    "    client = clients[client_idx]\n",
    "    data = client.data\n",
    "    labels = client.labels\n",
    "    clss_indices = jnp.where(labels == cfg.data.poison.source_clss)[0]\n",
    "    num_attack_samples = int(cfg.data.poison.ratio * len(clss_indices))\n",
    "    key, subkey = jrd.split(key)\n",
    "    attack_idx = jrd.permutation(subkey, clss_indices)[:num_attack_samples]\n",
    "    attack_data = data[attack_idx,:, : ,:]\n",
    "    attack_labels = labels[attack_idx]\n",
    "    key, subkey = jrd.split(key)\n",
    "    subkeys = jrd.split(subkey, len(attack_idx))\n",
    "    poison_fn = jax.vmap(poison_image, in_axes=[0,0,None])\n",
    "    attack_data, l2_norms = poison_fn(subkeys, attack_data, cfg.data.poison)\n",
    "    print(attack_idx)\n",
    "    \n",
    "    client.data = client.data.at[attack_idx, :, :, :].set(attack_data)\n",
    "    client.labels = client.labels.at[attack_idx].set(jnp.array([cfg.data.poison.target_clss] * num_attack_samples))\n",
    "    client.poisoned_idx = attack_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2682 4261 3335 5098 9503 3890 5194 5862 1144 6028 2525 9841 2814 6491\n",
      "  739 6314 9234 2445 9391 1046 6053 9478 9337 9184 9298 8747 5420 6991\n",
      " 8035 8863 7583 8348 4463 6544 3960 9382 6909 5206 1911 1641 1281 1235\n",
      " 3619 9117  127 3636  129  978 7842 7826 5187 3788 3408  751 1146 9719\n",
      " 4076 2452 6598 3022 2556 8185 7393  779 9671 7155 7352 5451  120 2526\n",
      " 4056 5957  397 8909 4263 7974 6860 8089 3678 5432 7018 1684 2913 6573\n",
      " 2798 5207 4072 7108 4728 9338 1022  375 6386 9588 7511 4583 2207  711\n",
      " 4355 1102 5964 1089 7752 9427 7630  433   52 3462 6964 1637 2064  797\n",
      " 5223 3115 9349 2790 1460 9709 3295 6886 2616 2773  509 1087 8940 9133\n",
      " 1550    8 3537 5488 7542 2969  588 1032 6148 3345 9013 5735  207 5668\n",
      " 1406  970 8531 4315  283 1493 7777 5633 5374  347 6530 4338  785 7351\n",
      " 4271 5802  167 2909 8192 4830 2021 8072 2832 9583 9493 6522 6216 9616\n",
      " 5982  395 7315 8601 2339 4645 6952 2282 8823 4177]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ata/Desktop/Me/myvenvmetal/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=uint8 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = Client\n",
    "data = client.test_data\n",
    "labels = client.test_labels\n",
    "clss_indices = jnp.where(labels == cfg.data.poison.source_clss)[0]\n",
    "num_attack_samples = int(cfg.data.poison.ratio * len(clss_indices))\n",
    "key, subkey = jrd.split(key)\n",
    "attack_idx = jrd.permutation(subkey, clss_indices)[:num_attack_samples]\n",
    "attack_data = data[attack_idx,:, : ,:]\n",
    "attack_labels = labels[attack_idx]\n",
    "key, subkey = jrd.split(key)\n",
    "subkeys = jrd.split(subkey, len(attack_idx))\n",
    "poison_fn = jax.vmap(poison_image, in_axes=[0, 0, None])\n",
    "attack_data, l2_norms = poison_fn(subkeys, attack_data, cfg.data.poison)\n",
    "print(attack_idx)\n",
    "\n",
    "client.test_data = client.test_data.at[attack_idx, :, :, :].set(attack_data)\n",
    "client.test_labels = client.test_labels.at[attack_idx].set(jnp.array([cfg.data.poison.target_clss] * num_attack_samples))\n",
    "client.test_poisoned_idx = attack_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisoned Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x312351250>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(clients[0].data[clients[0].poisoned_idx[0]], cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server Model Initialization and Metrics Definition\n",
    "\n",
    "- **Random Key Splitting:**  \n",
    "  `key, smodel_key = jrd.split(key, 2)` splits the random key so that one part is used for server model initialization.\n",
    "\n",
    "- **Model Creation:**  \n",
    "  `smodel = get_model(cfg.train.model, cfg.data.num_classes)` retrieves the model defined in the configuration for the specified number of classes.\n",
    "\n",
    "- **Model Variables Initialization:**  \n",
    "  `svars = smodel.init(smodel_key, jnp.ones((cfg.data.batch_size, *cfg.data.shape)), train=True)` initializes the model parameters using a dummy input tensor (a batch of ones).\n",
    "\n",
    "- **Server Optimizer Setup:**  \n",
    "  `stx = cfg.server.tx.fn(cfg.server.tx.lr)` creates the server's optimizer with the configured learning rate, and `state_stx = stx.init(svars)` initializes the optimizer's state using the model variables.\n",
    "\n",
    "- **Client Optimizer Setup:**  \n",
    "  `client_tx = cfg.worker.tx.fn(cfg.worker.tx.lr, cfg.worker.tx.moment)` sets up the optimizer for clients with a learning rate and momentum from the configuration.\n",
    "\n",
    "- **Metrics Definition:**  \n",
    "  The `Metrics` dataclass, built using Flax's `struct.dataclass` and `metrics.Collection`, defines two metrics:  \n",
    "  - **loss:** Tracks the average loss.  \n",
    "  - **accuracy:** Tracks the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, smodel_key = jrd.split(key, 2)\n",
    "smodel = get_model(cfg.train.model, cfg.data.num_classes)\n",
    "\n",
    "svars = smodel.init(smodel_key, jnp.ones((cfg.data.batch_size, *cfg.data.shape)), train=True)\n",
    "stx = cfg.server.tx.fn(cfg.server.tx.lr)\n",
    "state_stx = stx.init(svars)\n",
    "client_tx = cfg.worker.tx.fn(cfg.worker.tx.lr, cfg.worker.tx.moment)\n",
    "\n",
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    loss: metrics.Average.from_output(\"loss\")\n",
    "    accuracy: metrics.Accuracy.from_output(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mata-shaker\u001b[0m (\u001b[33mcod-tum\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ata/Desktop/Me/JAX/wandb/run-20250216_221830-67fnv1p9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cod-tum/Federated%20Learning/runs/67fnv1p9' target=\"_blank\">bumbling-hill-1787</a></strong> to <a href='https://wandb.ai/cod-tum/Federated%20Learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cod-tum/Federated%20Learning' target=\"_blank\">https://wandb.ai/cod-tum/Federated%20Learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cod-tum/Federated%20Learning/runs/67fnv1p9' target=\"_blank\">https://wandb.ai/cod-tum/Federated%20Learning/runs/67fnv1p9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login()\n",
    "run = wandb.init(project=cfg.wandb.project, job_type=cfg.wandb.job_type,\n",
    "                config=cfg.to_dict(), name=cfg.wandb.name)\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server Training Loop and Logging\n",
    "\n",
    "- **Initialization:**  \n",
    "  - Create an empty DataFrame `log_df` to record training logs.\n",
    "  - Iterate over server epochs with `for server_epoch in range(cfg.server.num_epochs)`.\n",
    "\n",
    "- **Epoch Setup:**  \n",
    "  - Record the start time of the epoch.\n",
    "  - Initialize a `log_row` Series to store metrics and set a counter for active clients.\n",
    "  - Initialize aggregate gradient trees (`agg_grads` and `agg_grads_signs`) with zeros matching the shape of the model variables.\n",
    "\n",
    "- **Client Training:**  \n",
    "  - For each client in the client list:\n",
    "    - Check if the client is active during the current server epoch.\n",
    "    - If active:\n",
    "      - Split the random key to generate a client-specific key.\n",
    "      - Increment the active client counter.\n",
    "      - Initialize the client optimizer state.\n",
    "      - Train the client using `train_client` to compute gradients.\n",
    "      - Aggregate the client gradients into `agg_grads` and accumulate the sign of gradients into `agg_grads_signs`.\n",
    "\n",
    "- **Server Update:**  \n",
    "  - After processing all clients, compute the epoch duration.\n",
    "  - If the number of active clients meets the threshold:\n",
    "    - Compute a mask on the aggregated gradient signs based on a threshold (`cfg.rlr.thresh`).\n",
    "    - Average the aggregated gradients by the number of active clients.\n",
    "    - Apply the mask to obtain `agg_grads_rlr`.\n",
    "    - Update the server model parameters using the server optimizer (`stx`), and apply the computed updates.\n",
    "\n",
    "- **Evaluation and Logging:**  \n",
    "  - Test the updated server model on both test and validation datasets using `test_client`.\n",
    "  - Log the validation and test losses and accuracies.\n",
    "  - Additionally, test on poisoned (attack) samples and log these metrics.\n",
    "  - Record the epoch runtime in `log_row`.\n",
    "  - Append `log_row` to `log_df`.\n",
    "\n",
    "- **Finalization:**  \n",
    "  - Update Weights & Biases (wandb) configuration with the current settings.\n",
    "  - Finish the wandb run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Epoch 1 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 1 is completed in 6.042219 seconds.\n",
      "Server Epoch 2 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 2 is completed in 4.605809 seconds.\n",
      "Server Epoch 3 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 3 is completed in 4.642686 seconds.\n",
      "Server Epoch 4 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 4 is completed in 4.666828 seconds.\n",
      "Server Epoch 5 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 5 is completed in 4.661591 seconds.\n",
      "Server Epoch 6 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 6 is completed in 4.690381 seconds.\n",
      "Server Epoch 7 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 7 is completed in 4.738744 seconds.\n",
      "Server Epoch 8 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 8 is completed in 4.713116 seconds.\n",
      "Server Epoch 9 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 9 is completed in 4.7034 seconds.\n",
      "Server Epoch 10 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 10 is completed in 4.786985 seconds.\n",
      "Server Epoch 11 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 11 is completed in 4.71769 seconds.\n",
      "Server Epoch 12 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 12 is completed in 5.001281 seconds.\n",
      "Server Epoch 13 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 13 is completed in 4.95151 seconds.\n",
      "Server Epoch 14 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 14 is completed in 4.926768 seconds.\n",
      "Server Epoch 15 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 15 is completed in 4.71904 seconds.\n",
      "Server Epoch 16 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 16 is completed in 4.713448 seconds.\n",
      "Server Epoch 17 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 17 is completed in 4.883008 seconds.\n",
      "Server Epoch 18 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 18 is completed in 4.747256 seconds.\n",
      "Server Epoch 19 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 19 is completed in 4.768114 seconds.\n",
      "Server Epoch 20 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 20 is completed in 4.790201 seconds.\n",
      "Server Epoch 21 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 21 is completed in 4.767428 seconds.\n",
      "Server Epoch 22 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 22 is completed in 4.770983 seconds.\n",
      "Server Epoch 23 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 23 is completed in 4.752444 seconds.\n",
      "Server Epoch 24 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 24 is completed in 4.776869 seconds.\n",
      "Server Epoch 25 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 25 is completed in 4.902004 seconds.\n",
      "Server Epoch 26 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 26 is completed in 4.844235 seconds.\n",
      "Server Epoch 27 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 27 is completed in 4.846404 seconds.\n",
      "Server Epoch 28 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 28 is completed in 4.842083 seconds.\n",
      "Server Epoch 29 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 29 is completed in 4.861049 seconds.\n",
      "Server Epoch 30 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 30 is completed in 4.856924 seconds.\n",
      "Server Epoch 31 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 31 is completed in 4.823754 seconds.\n",
      "Server Epoch 32 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 32 is completed in 4.938665 seconds.\n",
      "Server Epoch 33 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 33 is completed in 4.881135 seconds.\n",
      "Server Epoch 34 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 34 is completed in 4.843902 seconds.\n",
      "Server Epoch 35 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 35 is completed in 4.877434 seconds.\n",
      "Server Epoch 36 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 36 is completed in 4.869862 seconds.\n",
      "Server Epoch 37 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 37 is completed in 4.956912 seconds.\n",
      "Server Epoch 38 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 38 is completed in 4.898538 seconds.\n",
      "Server Epoch 39 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 39 is completed in 4.879619 seconds.\n",
      "Server Epoch 40 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 40 is completed in 4.872893 seconds.\n",
      "Server Epoch 41 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 41 is completed in 5.013246 seconds.\n",
      "Server Epoch 42 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 42 is completed in 4.901916 seconds.\n",
      "Server Epoch 43 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 43 is completed in 4.89348 seconds.\n",
      "Server Epoch 44 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 44 is completed in 4.899672 seconds.\n",
      "Server Epoch 45 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 45 is completed in 4.88675 seconds.\n",
      "Server Epoch 46 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 46 is completed in 4.911146 seconds.\n",
      "Server Epoch 47 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 47 is completed in 4.877511 seconds.\n",
      "Server Epoch 48 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 48 is completed in 4.895081 seconds.\n",
      "Server Epoch 49 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 49 is completed in 5.008667 seconds.\n",
      "Server Epoch 50 Started...\n",
      "Training on Client 1...\n",
      "Training on Client 2...\n",
      "Training on Client 3...\n",
      "Training on Client 4...\n",
      "Training on Client 5...\n",
      "Training on Client 6...\n",
      "Training on Client 7...\n",
      "Training on Client 8...\n",
      "Training on Client 9...\n",
      "Training on Client 10...\n",
      "Server Epoch 50 is completed in 4.916797 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Server Attack Accuracy</td><td></td></tr><tr><td>Server Attack Test Loss</td><td></td></tr><tr><td>Server Run Time</td><td></td></tr><tr><td>Server Test Accuracy</td><td></td></tr><tr><td>Server Test Loss</td><td></td></tr><tr><td>Server Validation Accuracy</td><td></td></tr><tr><td>Server Validation Loss</td><td></td></tr><tr><td>Worker 1's Local Accuracy</td><td></td></tr><tr><td>Worker 1's Local Loss</td><td></td></tr><tr><td>Worker 1's Test Accuracy</td><td></td></tr><tr><td>Worker 1's Test Loss</td><td></td></tr><tr><td>Worker 1's Validation Accuracy</td><td></td></tr><tr><td>Worker 1's Validation Loss</td><td></td></tr><tr><td>Worker 10's Local Accuracy</td><td></td></tr><tr><td>Worker 10's Local Loss</td><td></td></tr><tr><td>Worker 10's Test Accuracy</td><td></td></tr><tr><td>Worker 10's Test Loss</td><td></td></tr><tr><td>Worker 10's Validation Accuracy</td><td></td></tr><tr><td>Worker 10's Validation Loss</td><td></td></tr><tr><td>Worker 2's Local Accuracy</td><td></td></tr><tr><td>Worker 2's Local Loss</td><td></td></tr><tr><td>Worker 2's Test Accuracy</td><td></td></tr><tr><td>Worker 2's Test Loss</td><td></td></tr><tr><td>Worker 2's Validation Accuracy</td><td></td></tr><tr><td>Worker 2's Validation Loss</td><td></td></tr><tr><td>Worker 3's Local Accuracy</td><td></td></tr><tr><td>Worker 3's Local Loss</td><td></td></tr><tr><td>Worker 3's Test Accuracy</td><td></td></tr><tr><td>Worker 3's Test Loss</td><td></td></tr><tr><td>Worker 3's Validation Accuracy</td><td></td></tr><tr><td>Worker 3's Validation Loss</td><td></td></tr><tr><td>Worker 4's Local Accuracy</td><td></td></tr><tr><td>Worker 4's Local Loss</td><td></td></tr><tr><td>Worker 4's Test Accuracy</td><td></td></tr><tr><td>Worker 4's Test Loss</td><td></td></tr><tr><td>Worker 4's Validation Accuracy</td><td></td></tr><tr><td>Worker 4's Validation Loss</td><td></td></tr><tr><td>Worker 5's Local Accuracy</td><td></td></tr><tr><td>Worker 5's Local Loss</td><td></td></tr><tr><td>Worker 5's Test Accuracy</td><td></td></tr><tr><td>Worker 5's Test Loss</td><td></td></tr><tr><td>Worker 5's Validation Accuracy</td><td></td></tr><tr><td>Worker 5's Validation Loss</td><td></td></tr><tr><td>Worker 6's Local Accuracy</td><td></td></tr><tr><td>Worker 6's Local Loss</td><td></td></tr><tr><td>Worker 6's Test Accuracy</td><td></td></tr><tr><td>Worker 6's Test Loss</td><td></td></tr><tr><td>Worker 6's Validation Accuracy</td><td></td></tr><tr><td>Worker 6's Validation Loss</td><td></td></tr><tr><td>Worker 7's Local Accuracy</td><td></td></tr><tr><td>Worker 7's Local Loss</td><td></td></tr><tr><td>Worker 7's Test Accuracy</td><td></td></tr><tr><td>Worker 7's Test Loss</td><td></td></tr><tr><td>Worker 7's Validation Accuracy</td><td></td></tr><tr><td>Worker 7's Validation Loss</td><td></td></tr><tr><td>Worker 8's Local Accuracy</td><td></td></tr><tr><td>Worker 8's Local Loss</td><td></td></tr><tr><td>Worker 8's Test Accuracy</td><td></td></tr><tr><td>Worker 8's Test Loss</td><td></td></tr><tr><td>Worker 8's Validation Accuracy</td><td></td></tr><tr><td>Worker 8's Validation Loss</td><td></td></tr><tr><td>Worker 9's Local Accuracy</td><td></td></tr><tr><td>Worker 9's Local Loss</td><td></td></tr><tr><td>Worker 9's Test Accuracy</td><td></td></tr><tr><td>Worker 9's Test Loss</td><td></td></tr><tr><td>Worker 9's Validation Accuracy</td><td></td></tr><tr><td>Worker 9's Validation Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Server Attack Accuracy</td><td>0.38202</td></tr><tr><td>Server Attack Test Loss</td><td>1.43223</td></tr><tr><td>Server Run Time</td><td>4.9168</td></tr><tr><td>Server Test Accuracy</td><td>0.9672</td></tr><tr><td>Server Test Loss</td><td>0.09159</td></tr><tr><td>Server Validation Accuracy</td><td>0.978</td></tr><tr><td>Server Validation Loss</td><td>0.06126</td></tr><tr><td>Worker 1's Local Accuracy</td><td>0.98366</td></tr><tr><td>Worker 1's Local Loss</td><td>0.0604</td></tr><tr><td>Worker 1's Test Accuracy</td><td>0.9728</td></tr><tr><td>Worker 1's Test Loss</td><td>0.08075</td></tr><tr><td>Worker 1's Validation Accuracy</td><td>0.973</td></tr><tr><td>Worker 1's Validation Loss</td><td>0.07916</td></tr><tr><td>Worker 10's Local Accuracy</td><td>0.98597</td></tr><tr><td>Worker 10's Local Loss</td><td>0.05178</td></tr><tr><td>Worker 10's Test Accuracy</td><td>0.972</td></tr><tr><td>Worker 10's Test Loss</td><td>0.0866</td></tr><tr><td>Worker 10's Validation Accuracy</td><td>0.976</td></tr><tr><td>Worker 10's Validation Loss</td><td>0.07468</td></tr><tr><td>Worker 2's Local Accuracy</td><td>0.981</td></tr><tr><td>Worker 2's Local Loss</td><td>0.06533</td></tr><tr><td>Worker 2's Test Accuracy</td><td>0.9559</td></tr><tr><td>Worker 2's Test Loss</td><td>0.12743</td></tr><tr><td>Worker 2's Validation Accuracy</td><td>0.977</td></tr><tr><td>Worker 2's Validation Loss</td><td>0.07609</td></tr><tr><td>Worker 3's Local Accuracy</td><td>0.981</td></tr><tr><td>Worker 3's Local Loss</td><td>0.05965</td></tr><tr><td>Worker 3's Test Accuracy</td><td>0.9636</td></tr><tr><td>Worker 3's Test Loss</td><td>0.10092</td></tr><tr><td>Worker 3's Validation Accuracy</td><td>0.973</td></tr><tr><td>Worker 3's Validation Loss</td><td>0.0762</td></tr><tr><td>Worker 4's Local Accuracy</td><td>0.98295</td></tr><tr><td>Worker 4's Local Loss</td><td>0.05718</td></tr><tr><td>Worker 4's Test Accuracy</td><td>0.9602</td></tr><tr><td>Worker 4's Test Loss</td><td>0.1184</td></tr><tr><td>Worker 4's Validation Accuracy</td><td>0.979</td></tr><tr><td>Worker 4's Validation Loss</td><td>0.07017</td></tr><tr><td>Worker 5's Local Accuracy</td><td>0.981</td></tr><tr><td>Worker 5's Local Loss</td><td>0.06212</td></tr><tr><td>Worker 5's Test Accuracy</td><td>0.965</td></tr><tr><td>Worker 5's Test Loss</td><td>0.10461</td></tr><tr><td>Worker 5's Validation Accuracy</td><td>0.979</td></tr><tr><td>Worker 5's Validation Loss</td><td>0.07506</td></tr><tr><td>Worker 6's Local Accuracy</td><td>0.98136</td></tr><tr><td>Worker 6's Local Loss</td><td>0.0583</td></tr><tr><td>Worker 6's Test Accuracy</td><td>0.9662</td></tr><tr><td>Worker 6's Test Loss</td><td>0.09635</td></tr><tr><td>Worker 6's Validation Accuracy</td><td>0.978</td></tr><tr><td>Worker 6's Validation Loss</td><td>0.06872</td></tr><tr><td>Worker 7's Local Accuracy</td><td>0.9826</td></tr><tr><td>Worker 7's Local Loss</td><td>0.05834</td></tr><tr><td>Worker 7's Test Accuracy</td><td>0.9614</td></tr><tr><td>Worker 7's Test Loss</td><td>0.10732</td></tr><tr><td>Worker 7's Validation Accuracy</td><td>0.977</td></tr><tr><td>Worker 7's Validation Loss</td><td>0.07121</td></tr><tr><td>Worker 8's Local Accuracy</td><td>0.97869</td></tr><tr><td>Worker 8's Local Loss</td><td>0.07306</td></tr><tr><td>Worker 8's Test Accuracy</td><td>0.9594</td></tr><tr><td>Worker 8's Test Loss</td><td>0.1194</td></tr><tr><td>Worker 8's Validation Accuracy</td><td>0.977</td></tr><tr><td>Worker 8's Validation Loss</td><td>0.08461</td></tr><tr><td>Worker 9's Local Accuracy</td><td>0.97887</td></tr><tr><td>Worker 9's Local Loss</td><td>0.07</td></tr><tr><td>Worker 9's Test Accuracy</td><td>0.9595</td></tr><tr><td>Worker 9's Test Loss</td><td>0.12752</td></tr><tr><td>Worker 9's Validation Accuracy</td><td>0.976</td></tr><tr><td>Worker 9's Validation Loss</td><td>0.07474</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-hill-1787</strong> at: <a href='https://wandb.ai/cod-tum/Federated%20Learning/runs/67fnv1p9' target=\"_blank\">https://wandb.ai/cod-tum/Federated%20Learning/runs/67fnv1p9</a><br> View project at: <a href='https://wandb.ai/cod-tum/Federated%20Learning' target=\"_blank\">https://wandb.ai/cod-tum/Federated%20Learning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250216_221830-67fnv1p9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_df = pd.DataFrame()\n",
    "for server_epoch in range(cfg.server.num_epochs):\n",
    "    epoch_start_time = datetime.now()\n",
    "    print(f\"Server Epoch {server_epoch + 1} Started...\")\n",
    "    log_row = pd.Series()\n",
    "    num_active_clients = 0\n",
    "    # agg_params = jax.tree.map(lambda x: jnp.zeros_like(x), svars)\n",
    "    agg_grads = jtr.map(lambda x: jnp.zeros_like(x), svars)\n",
    "    agg_grads_signs = jtr.map(lambda x: jnp.zeros_like(x), svars)\n",
    "\n",
    "    for client in clients:\n",
    "        if client.active[server_epoch]:\n",
    "            print(f\"Training on Client {client.client_id + 1}...\")\n",
    "            key, client_key = jrd.split(key)\n",
    "            num_active_clients += 1\n",
    "            state_client_tx = client_tx.init(svars)\n",
    "            # client_params, log_row = train_client(client_key, client, smodel,\n",
    "            #                             svars, client_tx,\n",
    "            #                             state_client_tx, cfg.train.loss_fn, \n",
    "            #                             client.epochs[server_epoch],\n",
    "            #                             cfg.data.batch_size, num_classes,\n",
    "            #                                 cfg.train.batchwise_update, log_row)\n",
    "            # agg_params = jax.tree.map(lambda x, y: x + y, agg_params, client_params)\n",
    "            \n",
    "            client_grad = train_client(client_key, client, smodel,\n",
    "                            svars, client_tx,\n",
    "                            state_client_tx, cfg.train.loss_fn,\n",
    "                            client.epochs[server_epoch],\n",
    "                            cfg.data.batch_size, num_classes,\n",
    "                            cfg.train.batchwise_update,\n",
    "                            log_row,\n",
    "                            cfg.quantization)\n",
    "            agg_grads = jax.tree.map(lambda x, y: x + y, agg_grads, client_grad)\n",
    "            agg_grads_signs = jax.tree.map(lambda x, y: x + jnp.sign(y), agg_grads_signs, client_grad)\n",
    "    \n",
    "    epoch_end_time = datetime.now()\n",
    "\n",
    "    if num_active_clients >= len(clients) * cfg.server.update_thresh:\n",
    "        # agg_params = jax.tree.map(lambda x: x / num_active_clients, agg_params)\n",
    "        # svars = agg_params\n",
    "        # agg_grads = jax.tree.map(lambda x, y: x - y, svars, agg_params)\n",
    "        # updates, state_server_tx = server_tx.update(agg_grads, state_server_tx, svars)\n",
    "        # svars = optax.apply_updates(client_params, updates)\n",
    "        \n",
    "        agg_grads_signs_mask = jtr.map(lambda x: jnp.abs(x) >= cfg.rlr.thresh, agg_grads_signs)\n",
    "        agg_grads = jax.tree.map(lambda x: x / num_active_clients, agg_grads)\n",
    "        agg_grads_rlr = otu.tree_mul(agg_grads_signs_mask, agg_grads)\n",
    "        updates, state_server_tx = stx.update(agg_grads_rlr, state_stx, svars)\n",
    "        svars = optax.apply_updates(svars, updates)        \n",
    "\n",
    "        # for label_clss in jnp.unique(Client.test_labels):\n",
    "        #     tindices = jnp.where(Client.test_labels == label_clss)[0]\n",
    "        #     vindices = jnp.where(Client.valid_labels == label_clss)[0]\n",
    "        #     tdata = Client.test_data[tindices]\n",
    "        #     tlabels = Client.test_data[tindices]\n",
    "        #     vdata = Client.valid_data[vindices]\n",
    "        #     vlabels = Client.valid_labels[vindices]\n",
    "        #     test_loss, test_acc = test_client(smodel, svars, cfg.train.loss_fn, tdata, tlabels, num_classes)\n",
    "        #     valid_loss, valid_acc = test_client(smodel, svars, cfg.train.loss_fn, vdata, vlabels, num_classes)\n",
    "        #     log_row = log(log_row, server_epoch, \n",
    "        #                     {f\"Server Validation Loss {label_clss}\": valid_loss, \n",
    "        #                     f\"Server Validation Accuracy {label_clss}\": valid_acc,\n",
    "        #                     f\"Server Test Loss {label_clss}\": test_loss, \n",
    "        #                     f\"Server Test Accuracy {label_clss}\": test_acc})\n",
    "\n",
    "        test_loss, test_acc = test_client(smodel, svars, cfg.train.loss_fn, Client.test_data, Client.test_labels, num_classes)\n",
    "        valid_loss, valid_acc = test_client(smodel, svars, cfg.train.loss_fn, Client.valid_data, Client.valid_labels, num_classes)\n",
    "        log_row = log(log_row, server_epoch, \n",
    "                        {\"Server Validation Loss\": valid_loss, \n",
    "                        \"Server Validation Accuracy\": valid_acc,\n",
    "                        \"Server Test Loss\": test_loss, \n",
    "                        \"Server Test Accuracy\": test_acc})\n",
    "\n",
    "        attack_data = Client.test_data[Client.test_poisoned_idx]\n",
    "        attack_labels = Client.test_labels[Client.test_poisoned_idx]\n",
    "        attack_loss, attack_acc = test_client(smodel, svars, cfg.train.loss_fn, attack_data, attack_labels, num_classes)\n",
    "        log_row = log(log_row, server_epoch, \n",
    "                        {\"Server Attack Test Loss\": attack_loss, \n",
    "                        \"Server Attack Accuracy\": attack_acc})\n",
    "        \n",
    "        # print(f\"Server Validation Loss: {valid_loss}, Server Validation Accuracy: {valid_acc}\")\n",
    "        # print(f\"Server Test Loss: {test_loss}, Server Test Accuracy: {test_acc}\")\n",
    "    else:\n",
    "        print(\"Not enough active clients to update the server model\")\n",
    "        print(f\"Server Epoch {server_epoch + 1} skipped...\")\n",
    "    \n",
    "    print(f'Server Epoch {server_epoch + 1} is completed in {(epoch_end_time - epoch_start_time).total_seconds()} seconds.')\n",
    "    log_row = log(log_row, server_epoch, {f'Server Run Time': (epoch_end_time - epoch_start_time).total_seconds()})\n",
    "    if log_df.empty:\n",
    "        log_df = log_row.to_frame().T\n",
    "    else:\n",
    "        log_df.loc[len(log_df)] = log_row\n",
    "\n",
    "log_df['Run'] = cfg.wandb.name\n",
    "wandb.config.update(cfg.to_dict(), allow_val_change=True)\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenvmetal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
